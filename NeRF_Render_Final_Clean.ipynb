{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF Rendering from Checkpoint (Original Repo)\n",
    "\n",
    "**Loads your trained model and renders test images**\n",
    "\n",
    "**Requirements:**\n",
    "1. Upload `results.zip` to this Colab\n",
    "2. Mount Google Drive (must have lego dataset)\n",
    "\n",
    "**Time:** ~20 minutes for 3 images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nCUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload results.zip\n",
    "\n",
    "**Click the folder icon on left → Upload → Select your results.zip**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "if os.path.exists('results.zip'):\n",
    "    print(\"✓ results.zip found\")\n",
    "    !ls -lh results.zip\n",
    "else:\n",
    "    print(\"✗ Please upload results.zip first!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✓ Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset from Drive\n",
    "!mkdir -p data/nerf_synthetic\n",
    "!cp -r /content/drive/MyDrive/data/nerf_synthetic/lego data/nerf_synthetic/\n",
    "\n",
    "print(\"✓ Dataset copied\")\n",
    "!ls data/nerf_synthetic/lego/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Fix Dataset JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Fix JSON files\n",
    "for split in ['train', 'val', 'test']:\n",
    "    json_path = f'data/nerf_synthetic/lego/transforms_{split}.json'\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    split_dir = f'data/nerf_synthetic/lego/{split}'\n",
    "    actual_files = sorted([f.replace('.png', '') for f in os.listdir(split_dir) \n",
    "                          if f.endswith('.png') and 'depth' not in f])\n",
    "    \n",
    "    for i, frame in enumerate(data['frames']):\n",
    "        if i < len(actual_files):\n",
    "            data['frames'][i]['file_path'] = f\"./{split}/{actual_files[i]}\"\n",
    "    \n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Fixed {split}\")\n",
    "\n",
    "print(\"\\n✓ Dataset ready\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Clone Original NeRF Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the ORIGINAL NeRF implementation\n",
    "!rm -rf nerf-pytorch\n",
    "!git clone https://github.com/yenchenlin/nerf-pytorch.git\n",
    "\n",
    "print(\"\\n✓ Original NeRF repo cloned\")\n",
    "!ls nerf-pytorch/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio imageio-ffmpeg configargparse -q\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Extract Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract results.zip\n",
    "!unzip -q results.zip\n",
    "\n",
    "# Find checkpoint\n",
    "import glob\n",
    "\n",
    "checkpoints = glob.glob('results/logs/lego_metrics/*.tar')\n",
    "if not checkpoints:\n",
    "    checkpoints = glob.glob('logs/lego_metrics/*.tar')\n",
    "\n",
    "if checkpoints:\n",
    "    checkpoint_path = checkpoints[0]\n",
    "    print(f\"✓ Found checkpoint: {checkpoint_path}\")\n",
    "else:\n",
    "    print(\"✗ Checkpoint not found!\")\n",
    "    !find . -name \"*.tar\" -type f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Render Images\n",
    "\n",
    "**This will take ~20 minutes for 3 images at half resolution**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, 'nerf-pytorch')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "\n",
    "from run_nerf_helpers import *\n",
    "from run_nerf import render\n",
    "from load_blender import load_blender_data\n",
    "\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "print(\"Loading dataset at HALF resolution...\")\n",
    "images, poses, render_poses, hwf, i_split = load_blender_data(\n",
    "    'data/nerf_synthetic/lego', \n",
    "    half_res=True,\n",
    "    testskip=8\n",
    ")\n",
    "i_train, i_val, i_test = i_split\n",
    "H, W, focal = hwf\n",
    "H, W = int(H), int(W)\n",
    "\n",
    "print(f\"Rendering at {H}x{W} (half resolution = faster)\")\n",
    "\n",
    "K = torch.Tensor([[focal, 0, 0.5*W], [0, focal, 0.5*H], [0, 0, 1]])\n",
    "\n",
    "# Only render 3 test images\n",
    "test_indices = i_test[:3]\n",
    "print(f\"Will render {len(test_indices)} test images\")\n",
    "\n",
    "print(\"\\nLoading checkpoint...\")\n",
    "checkpoint = torch.load(checkpoint_path, map_location='cpu')\n",
    "print(f\"Checkpoint loaded from: {checkpoint_path}\")\n",
    "\n",
    "# Create models\n",
    "embed_fn, input_ch = get_embedder(10, 0)\n",
    "embeddirs_fn, input_ch_views = get_embedder(4, 0)\n",
    "\n",
    "model = NeRF(D=8, W=256, input_ch=input_ch, output_ch=4, skips=[4], \n",
    "             input_ch_views=input_ch_views, use_viewdirs=True)\n",
    "model_fine = NeRF(D=8, W=256, input_ch=input_ch, output_ch=4, skips=[4], \n",
    "                  input_ch_views=input_ch_views, use_viewdirs=True)\n",
    "\n",
    "model.load_state_dict(checkpoint['network_fn_state_dict'])\n",
    "model_fine.load_state_dict(checkpoint['network_fine_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "model_fine.eval()\n",
    "\n",
    "print(\"✓ Models loaded\")\n",
    "\n",
    "# Network query function\n",
    "def network_query_fn(inputs, viewdirs, network_fn):\n",
    "    inputs_flat = torch.reshape(inputs, [-1, inputs.shape[-1]])\n",
    "    embedded = embed_fn(inputs_flat)\n",
    "    \n",
    "    if viewdirs is not None:\n",
    "        input_dirs = viewdirs[:,None].expand(inputs.shape)\n",
    "        input_dirs_flat = torch.reshape(input_dirs, [-1, input_dirs.shape[-1]])\n",
    "        embedded_dirs = embeddirs_fn(input_dirs_flat)\n",
    "        embedded = torch.cat([embedded, embedded_dirs], -1)\n",
    "    \n",
    "    outputs_flat = network_fn(embedded)\n",
    "    outputs = torch.reshape(outputs_flat, list(inputs.shape[:-1]) + [outputs_flat.shape[-1]])\n",
    "    return outputs\n",
    "\n",
    "# Rendering kwargs\n",
    "render_kwargs_test = {\n",
    "    'network_query_fn': network_query_fn,\n",
    "    'network_fn': model,\n",
    "    'network_fine': model_fine,\n",
    "    'N_samples': 32,\n",
    "    'N_importance': 64,\n",
    "    'perturb': False,\n",
    "    'white_bkgd': True,\n",
    "    'raw_noise_std': 0.,\n",
    "    'near': 2.,\n",
    "    'far': 6.,\n",
    "    'use_viewdirs': True\n",
    "}\n",
    "\n",
    "os.makedirs('nerf_renders', exist_ok=True)\n",
    "\n",
    "print(\"\\nStarting render (CPU - will take ~7 mins per image)...\\n\")\n",
    "\n",
    "with torch.no_grad():\n",
    "    for i, idx in enumerate(test_indices):\n",
    "        start = time.time()\n",
    "        print(f\"Rendering image {i+1}/3 (index {idx})...\")\n",
    "        \n",
    "        pose = torch.Tensor(poses[idx, :3, :4])\n",
    "        \n",
    "        rgb, disp, acc, extras = render(H, W, K, chunk=256, c2w=pose, **render_kwargs_test)\n",
    "        \n",
    "        rgb8 = (np.clip(rgb.numpy(), 0, 1) * 255).astype(np.uint8)\n",
    "        filename = f'nerf_renders/test_{idx:03d}.png'\n",
    "        imageio.imwrite(filename, rgb8)\n",
    "        \n",
    "        elapsed = time.time() - start\n",
    "        print(f\"✓ Image {i+1}/3 saved to {filename} ({elapsed:.1f}s)\\n\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"✓✓✓ RENDERING COMPLETE!\")\n",
    "print(\"=\"*60)\n",
    "print(\"\\nImages saved to: nerf_renders/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "imgs = sorted(glob.glob('nerf_renders/*.png'))\n",
    "\n",
    "print(f\"Rendered {len(imgs)} images:\\n\")\n",
    "\n",
    "for img in imgs:\n",
    "    print(f\"\\n{img}:\")\n",
    "    display(Image(img, width=500))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Zip renders\n",
    "!zip -r nerf_final_images.zip nerf_renders/\n",
    "\n",
    "print(\"✓ Images zipped\")\n",
    "\n",
    "# Download\n",
    "files.download('nerf_final_images.zip')\n",
    "\n",
    "print(\"\\n✓ Download complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## If Images Are Still White/Bad:\n",
    "\n",
    "**Your checkpoint didn't train properly.** Options:\n",
    "\n",
    "1. **Retrain from scratch** (~6 hours for proper training)\n",
    "2. **Use metrics only** + teammate's 3DGS images\n",
    "3. **Ask teammate to train NeRF** with nerfstudio (~30 mins)\n",
    "\n",
    "The checkpoint is from 10k iterations which may not be enough for good quality."
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
