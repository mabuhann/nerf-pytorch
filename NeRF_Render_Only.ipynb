{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF Rendering from Checkpoint\n",
    "\n",
    "**Load your trained NeRF model and render test images**\n",
    "\n",
    "**Time:** ~5-10 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nCUDA: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Upload Your results.zip\n",
    "\n",
    "Click the folder icon on the left → Upload → Select your `results.zip` file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify upload\n",
    "import os\n",
    "\n",
    "if os.path.exists('results.zip'):\n",
    "    print(\"✓ results.zip found!\")\n",
    "    !ls -lh results.zip\n",
    "else:\n",
    "    print(\"✗ results.zip not found. Please upload it first.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Extract Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the zip file\n",
    "!unzip -q results.zip\n",
    "\n",
    "print(\"✓ Extracted\")\n",
    "print(\"\\nContents:\")\n",
    "!ls -lh results/logs/lego_metrics/ 2>/dev/null || !ls -lh logs/lego_metrics/ 2>/dev/null || echo \"Checking structure...\"\n",
    "!ls results/ 2>/dev/null || !ls logs/ 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Mount Google Drive for Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"✓ Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Setup Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset\n",
    "!mkdir -p data/nerf_synthetic\n",
    "!cp -r /content/drive/MyDrive/data/nerf_synthetic/lego data/nerf_synthetic/\n",
    "\n",
    "print(\"✓ Dataset copied\")\n",
    "!ls data/nerf_synthetic/lego/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Fix Dataset JSON Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "# Fix JSON files to match actual image filenames\n",
    "for split in ['train', 'val', 'test']:\n",
    "    json_path = f'data/nerf_synthetic/lego/transforms_{split}.json'\n",
    "    \n",
    "    with open(json_path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    # Get actual files\n",
    "    split_dir = f'data/nerf_synthetic/lego/{split}'\n",
    "    actual_files = sorted([f.replace('.png', '') for f in os.listdir(split_dir) \n",
    "                          if f.endswith('.png') and 'depth' not in f])\n",
    "    \n",
    "    # Update frame paths\n",
    "    for i, frame in enumerate(data['frames']):\n",
    "        if i < len(actual_files):\n",
    "            data['frames'][i]['file_path'] = f\"./{split}/{actual_files[i]}\"\n",
    "    \n",
    "    # Save\n",
    "    with open(json_path, 'w') as f:\n",
    "        json.dump(data, f, indent=2)\n",
    "    \n",
    "    print(f\"✓ Fixed {split}\")\n",
    "\n",
    "print(\"\\n✓ Dataset ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Clone NeRF Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone your NeRF repo\n",
    "!git clone https://github.com/mabuhann/nerf-pytorch.git nerf_code\n",
    "\n",
    "print(\"✓ Code cloned\")\n",
    "!ls nerf_code/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio imageio-ffmpeg configargparse scikit-image -q\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Find the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "\n",
    "# Find checkpoint file\n",
    "# Structure: results/logs/lego_metrics/010000/*.tar\n",
    "checkpoints = glob.glob('results/logs/lego_metrics/010000/*.tar')\n",
    "\n",
    "if not checkpoints:\n",
    "    # Try alternate locations\n",
    "    checkpoints = glob.glob('logs/lego_metrics/010000/*.tar')\n",
    "\n",
    "if checkpoints:\n",
    "    checkpoint = checkpoints[0]\n",
    "    print(f\"✓ Found checkpoint: {checkpoint}\")\n",
    "else:\n",
    "    print(\"✗ No checkpoint found!\")\n",
    "    print(\"\\nLet's check what was extracted:\")\n",
    "    !ls -R results/ 2>/dev/null || !ls -R logs/ 2>/dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Render Test Images\n",
    "\n",
    "**This will render 10 test images using your trained model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create render script\n",
    "render_script = f\"\"\"\n",
    "import sys\n",
    "sys.path.insert(0, 'nerf_code')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import imageio\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Import NeRF functions\n",
    "from run_nerf_helpers import *\n",
    "from load_blender import load_blender_data\n",
    "\n",
    "# Load dataset\n",
    "print(\"Loading dataset...\")\n",
    "images, poses, render_poses, hwf, i_split = load_blender_data(\n",
    "    'data/nerf_synthetic/lego', \n",
    "    half_res=False, \n",
    "    testskip=1\n",
    ")\n",
    "i_train, i_val, i_test = i_split\n",
    "H, W, focal = hwf\n",
    "H, W = int(H), int(W)\n",
    "\n",
    "# Only render first 10 test images\n",
    "test_indices = i_test[:10]\n",
    "\n",
    "print(f\"Rendering {{len(test_indices)}} test images...\")\n",
    "\n",
    "# Load checkpoint\n",
    "print(\"Loading checkpoint...\")\n",
    "checkpoint = torch.load('{checkpoint}', map_location='cpu')\n",
    "\n",
    "# Create model\n",
    "render_kwargs_test = {{}}\n",
    "\n",
    "# Model architecture from original training\n",
    "embed_fn, input_ch = get_embedder(10, 0)\n",
    "embeddirs_fn, input_ch_views = get_embedder(4, 0)\n",
    "\n",
    "model = NeRF(\n",
    "    D=8, W=256,\n",
    "    input_ch=input_ch, \n",
    "    output_ch=4, \n",
    "    skips=[4],\n",
    "    input_ch_views=input_ch_views, \n",
    "    use_viewdirs=True\n",
    ").cuda()\n",
    "\n",
    "model_fine = NeRF(\n",
    "    D=8, W=256,\n",
    "    input_ch=input_ch, \n",
    "    output_ch=4, \n",
    "    skips=[4],\n",
    "    input_ch_views=input_ch_views, \n",
    "    use_viewdirs=True\n",
    ").cuda()\n",
    "\n",
    "# Load weights\n",
    "model.load_state_dict(checkpoint['network_fn_state_dict'])\n",
    "model_fine.load_state_dict(checkpoint['network_fine_state_dict'])\n",
    "\n",
    "model.eval()\n",
    "model_fine.eval()\n",
    "\n",
    "# Setup rendering kwargs\n",
    "render_kwargs_test['network_fn'] = model\n",
    "render_kwargs_test['network_fine'] = model_fine\n",
    "render_kwargs_test['embed_fn'] = embed_fn\n",
    "render_kwargs_test['embeddirs_fn'] = embeddirs_fn\n",
    "render_kwargs_test['N_samples'] = 64\n",
    "render_kwargs_test['N_importance'] = 128\n",
    "render_kwargs_test['perturb'] = False\n",
    "render_kwargs_test['white_bkgd'] = True\n",
    "render_kwargs_test['raw_noise_std'] = 0.\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs('nerf_renders', exist_ok=True)\n",
    "\n",
    "# Render images\n",
    "with torch.no_grad():\n",
    "    for idx in tqdm(test_indices):\n",
    "        pose = poses[idx, :3, :4]\n",
    "        \n",
    "        # Render\n",
    "        rgb, disp, acc, extras = render(\n",
    "            H, W, focal, \n",
    "            chunk=1024*32,\n",
    "            c2w=pose,\n",
    "            **render_kwargs_test\n",
    "        )\n",
    "        \n",
    "        # Save\n",
    "        rgb8 = (np.clip(rgb.cpu().numpy(), 0, 1) * 255).astype(np.uint8)\n",
    "        filename = f'nerf_renders/test_{{idx:03d}}.png'\n",
    "        imageio.imwrite(filename, rgb8)\n",
    "\n",
    "print(f\"\\\\n✓ Rendered {{len(test_indices)}} images to nerf_renders/\")\n",
    "\"\"\"\n",
    "\n",
    "# Save and run\n",
    "with open('render_nerf.py', 'w') as f:\n",
    "    f.write(render_script)\n",
    "\n",
    "print(\"✓ Render script created\")\n",
    "print(\"\\nRunning rendering...\\n\")\n",
    "\n",
    "!python render_nerf.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: View Rendered Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Image, display\n",
    "import glob\n",
    "\n",
    "# Get rendered images\n",
    "rendered = sorted(glob.glob('nerf_renders/*.png'))\n",
    "\n",
    "print(f\"Rendered {len(rendered)} images:\\n\")\n",
    "\n",
    "for img in rendered:\n",
    "    print(f\"\\n{img}:\")\n",
    "    display(Image(img, width=400))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 12: Download Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Zip the renders\n",
    "!zip -r nerf_rendered_images.zip nerf_renders/\n",
    "\n",
    "print(\"✓ Images zipped\")\n",
    "\n",
    "# Download\n",
    "files.download('nerf_rendered_images.zip')\n",
    "\n",
    "print(\"\\n✓ Download complete!\")\n",
    "print(\"\\nYou now have NeRF rendered images for your comparison!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
