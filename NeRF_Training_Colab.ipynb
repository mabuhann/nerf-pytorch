{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF Training on Google Colab\n",
    "\n",
    "**GitHub Repo**: https://github.com/mabuhann/nerf-pytorch\n",
    "\n",
    "**Dataset**: Google Drive\n",
    "\n",
    "**Expected Runtime**: 4-6 hours on T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone GitHub Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/mabuhann/nerf-pytorch.git\n",
    "%cd nerf-pytorch\n",
    "\n",
    "print(\"\\n✓ Repo cloned\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Mount Google Drive and Copy Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✓ Drive mounted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy dataset from your Google Drive\n",
    "# Adjust the path if your folder structure is different\n",
    "\n",
    "import os\n",
    "\n",
    "# Create data directory\n",
    "!mkdir -p data/nerf_synthetic\n",
    "\n",
    "# Copy the lego dataset from Drive\n",
    "# This assumes you have a 'lego' folder in the Drive link you shared\n",
    "!cp -r /content/drive/MyDrive/lego data/nerf_synthetic/\n",
    "\n",
    "# If your Drive structure is different, it might be:\n",
    "# !cp -r \"/content/drive/MyDrive/Your Folder Name/lego\" data/nerf_synthetic/\n",
    "\n",
    "print(\"\\n✓ Dataset copied\")\n",
    "\n",
    "# Verify dataset\n",
    "print(\"\\nChecking dataset files:\")\n",
    "!ls data/nerf_synthetic/lego/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio imageio-ffmpeg configargparse scikit-image -q\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"Checking files...\\n\")\n",
    "\n",
    "# Check Python files\n",
    "required = ['run_nerf_with_metrics.py', 'run_nerf_helpers.py', 'load_blender.py']\n",
    "for f in required:\n",
    "    print(f\"{'✓' if os.path.exists(f) else '✗'} {f}\")\n",
    "\n",
    "# Check config\n",
    "print(f\"\\n{'✓' if os.path.exists('configs/lego_config.txt') else '✗'} configs/lego_config.txt\")\n",
    "\n",
    "# Check dataset transforms\n",
    "print(\"\\nDataset:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    path = f'data/nerf_synthetic/lego/transforms_{split}.json'\n",
    "    if os.path.exists(path):\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"✓ {split}: {len(data['frames'])} images\")\n",
    "    else:\n",
    "        print(f\"✗ {split}: not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Start Training\n",
    "\n",
    "**This will take 4-6 hours**\n",
    "\n",
    "Keep the browser tab open or use Colab Pro to avoid timeouts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python run_nerf_with_metrics.py --config configs/lego_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Show summary\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open('logs/lego_metrics/summary_metrics.json', 'r') as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "for key, value in summary.items():\n",
    "    if value is not None:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Show plot\n",
    "print(\"\\nTraining Plot:\")\n",
    "display(Image('logs/lego_metrics/training_metrics.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Analyze Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detailed analysis\n",
    "!python analyze_results.py \\\n",
    "    --log_dir logs/lego_metrics \\\n",
    "    --save_plot logs/lego_metrics/detailed_analysis.png\n",
    "\n",
    "# Show detailed plot\n",
    "print(\"\\nDetailed Analysis:\")\n",
    "display(Image('logs/lego_metrics/detailed_analysis.png'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Zip results\n",
    "!zip -r results.zip logs/lego_metrics/\n",
    "\n",
    "# Download\n",
    "files.download('results.zip')\n",
    "\n",
    "print(\"\\n✓ Download started\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Key Metrics for Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key metrics\n",
    "with open('logs/lego_metrics/summary_metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY METRICS FOR YOUR REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"Training Time: {metrics['total_training_time_hours']:.2f} hours\")\n",
    "print(f\"Test PSNR: {metrics['best_test_psnr']:.2f} dB\")\n",
    "print(f\"Test SSIM: {metrics['avg_test_ssim']:.4f}\")\n",
    "print(f\"Avg Step Time: {metrics['avg_step_time']:.4f} sec\")\n",
    "print(\"=\"*60)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
