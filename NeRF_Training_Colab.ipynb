{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF Training on Google Colab\n",
    "\n",
    "**GitHub Repo**: https://github.com/mabuhann/nerf-pytorch\n",
    "\n",
    "**Expected Runtime**: 4-6 hours on T4 GPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU\n",
    "\n",
    "**Make sure you enabled GPU runtime!**\n",
    "\n",
    "Runtime → Change runtime type → GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nCUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    print(\"\\n⚠️ WARNING: No GPU detected! Go to Runtime → Change runtime type → GPU\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone GitHub Repo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Clean up any existing directory\n",
    "!rm -rf nerf-pytorch\n",
    "\n",
    "# Clone the repo\n",
    "!git clone https://github.com/mabuhann/nerf-pytorch.git\n",
    "\n",
    "# Change to the directory\n",
    "%cd /content/nerf-pytorch\n",
    "\n",
    "print(\"\\n✓ Repo cloned\")\n",
    "print(f\"Working directory: {os.getcwd()}\")\n",
    "print(\"\\nFiles:\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Mount Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "print(\"\\n✓ Drive mounted\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Copy Dataset from Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create data directory structure\n",
    "!mkdir -p data/nerf_synthetic\n",
    "\n",
    "# Copy dataset from your Drive\n",
    "# Your dataset is at: /content/drive/MyDrive/data/nerf_synthetic/lego\n",
    "!cp -r /content/drive/MyDrive/data/nerf_synthetic/lego data/nerf_synthetic/\n",
    "\n",
    "print(\"\\n✓ Dataset copied\")\n",
    "\n",
    "# Verify the dataset\n",
    "print(\"\\nDataset contents:\")\n",
    "!ls -lh data/nerf_synthetic/lego/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install imageio imageio-ffmpeg configargparse scikit-image -q\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Verify Everything is Ready"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "\n",
    "print(\"Verification check:\\n\")\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "\n",
    "# Check Python files\n",
    "print(\"\\nPython files:\")\n",
    "required = ['run_nerf_with_metrics.py', 'run_nerf_helpers.py', 'load_blender.py']\n",
    "all_good = True\n",
    "for f in required:\n",
    "    exists = os.path.exists(f)\n",
    "    print(f\"{'✓' if exists else '✗'} {f}\")\n",
    "    if not exists:\n",
    "        all_good = False\n",
    "\n",
    "# Check config\n",
    "print(\"\\nConfig file:\")\n",
    "config_exists = os.path.exists('configs/lego_config.txt')\n",
    "print(f\"{'✓' if config_exists else '✗'} configs/lego_config.txt\")\n",
    "if not config_exists:\n",
    "    all_good = False\n",
    "\n",
    "# Check dataset\n",
    "print(\"\\nDataset:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    path = f'data/nerf_synthetic/lego/transforms_{split}.json'\n",
    "    exists = os.path.exists(path)\n",
    "    if exists:\n",
    "        with open(path) as f:\n",
    "            data = json.load(f)\n",
    "        print(f\"✓ {split}: {len(data['frames'])} images\")\n",
    "    else:\n",
    "        print(f\"✗ {split}: not found at {path}\")\n",
    "        all_good = False\n",
    "\n",
    "# Check actual image files\n",
    "print(\"\\nImage files:\")\n",
    "for split in ['train', 'val', 'test']:\n",
    "    img_dir = f'data/nerf_synthetic/lego/{split}'\n",
    "    if os.path.exists(img_dir):\n",
    "        n_images = len([f for f in os.listdir(img_dir) if f.endswith('.png')])\n",
    "        print(f\"✓ {split}: {n_images} .png files\")\n",
    "    else:\n",
    "        print(f\"✗ {split} directory not found\")\n",
    "        all_good = False\n",
    "\n",
    "if all_good:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✓ ALL CHECKS PASSED - READY TO TRAIN!\")\n",
    "    print(\"=\"*60)\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(\"✗ SOME CHECKS FAILED - FIX ERRORS BEFORE TRAINING\")\n",
    "    print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Start Training\n",
    "\n",
    "**⚠️ This will take 4-6 hours!**\n",
    "\n",
    "**Tips:**\n",
    "- Keep this browser tab open\n",
    "- Or use Colab Pro for longer sessions\n",
    "- Training will print progress every 100 iterations\n",
    "- Checkpoints saved every 10,000 iterations\n",
    "- Test evaluation every 25,000 iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python run_nerf_with_metrics.py --config configs/lego_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load and display summary\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open('logs/lego_metrics/summary_metrics.json', 'r') as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "for key, value in summary.items():\n",
    "    if value is not None:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display training plot\n",
    "print(\"\\nTraining Metrics:\")\n",
    "if os.path.exists('logs/lego_metrics/training_metrics.png'):\n",
    "    display(Image('logs/lego_metrics/training_metrics.png'))\n",
    "else:\n",
    "    print(\"Plot not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Detailed Analysis (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detailed analysis if available\n",
    "if os.path.exists('analyze_results.py'):\n",
    "    !python analyze_results.py \\\n",
    "        --log_dir logs/lego_metrics \\\n",
    "        --save_plot logs/lego_metrics/detailed_analysis.png\n",
    "    \n",
    "    # Display detailed plot\n",
    "    print(\"\\nDetailed Analysis:\")\n",
    "    if os.path.exists('logs/lego_metrics/detailed_analysis.png'):\n",
    "        display(Image('logs/lego_metrics/detailed_analysis.png'))\n",
    "else:\n",
    "    print(\"analyze_results.py not found - skipping detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Zip all results\n",
    "print(\"Zipping results...\")\n",
    "!zip -r results.zip logs/lego_metrics/\n",
    "\n",
    "print(\"\\nStarting download...\")\n",
    "files.download('results.zip')\n",
    "\n",
    "print(\"\\n✓ Download complete!\")\n",
    "print(\"\\nThe zip file contains:\")\n",
    "print(\"  - summary_metrics.json (key metrics)\")\n",
    "print(\"  - training_metrics.npz (all training data)\")\n",
    "print(\"  - test_metrics.npz (test evaluations)\")\n",
    "print(\"  - training_metrics.png (plots)\")\n",
    "print(\"  - Model checkpoints (.tar files)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Key Metrics for Your Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract key metrics for report\n",
    "with open('logs/lego_metrics/summary_metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY METRICS FOR YOUR REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Time: {metrics['total_training_time_hours']:.2f} hours\")\n",
    "print(f\"Test PSNR: {metrics['best_test_psnr']:.2f} dB\")\n",
    "print(f\"Test SSIM: {metrics['avg_test_ssim']:.4f}\")\n",
    "print(f\"Average Step Time: {metrics['avg_step_time']:.4f} seconds\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nCopy these values to compare with 3DGS!\")\n",
    "print(\"=\"*60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory?\n",
    "Run this to reduce memory usage, then restart from Step 7:\n",
    "\n",
    "```python\n",
    "# Reduce batch sizes\n",
    "with open('configs/lego_config.txt', 'r') as f:\n",
    "    config = f.read()\n",
    "\n",
    "config = config.replace('N_rand = 1024', 'N_rand = 512')\n",
    "config = config.replace('chunk = 8192', 'chunk = 4096')\n",
    "\n",
    "with open('configs/lego_config.txt', 'w') as f:\n",
    "    f.write(config)\n",
    "\n",
    "print(\"✓ Config updated for lower memory\")\n",
    "```\n",
    "\n",
    "### Session Timeout?\n",
    "- Use Colab Pro for 24-hour sessions\n",
    "- Keep browser tab active\n",
    "- Checkpoints are saved every 10k iterations - you can resume if needed\n",
    "\n",
    "### Files Not Found?\n",
    "- Make sure you ran all cells in order\n",
    "- Check Step 6 verification passed all checks\n",
    "- Verify your Drive path is correct in Step 4"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
