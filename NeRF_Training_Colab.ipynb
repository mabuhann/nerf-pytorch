{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NeRF Training on Google Colab (GitHub Version)\n",
    "\n",
    "This notebook trains NeRF on the LEGO dataset using files from GitHub.\n",
    "\n",
    "**Expected Runtime**: 4-6 hours on Colab GPU (T4)\n",
    "\n",
    "**GitHub Repo**: https://github.com/mabuhann/nerf-pytorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Check GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check GPU availability\n",
    "!nvidia-smi\n",
    "\n",
    "import torch\n",
    "print(f\"\\nPyTorch version: {torch.__version__}\")\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"CUDA version: {torch.version.cuda}\")\n",
    "    print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "    print(f\"GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Clone GitHub Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clone the GitHub repository\n",
    "!git clone https://github.com/mabuhann/nerf-pytorch.git\n",
    "\n",
    "print(\"\\n✓ Repository cloned\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Navigate to Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Change to repository directory\n",
    "os.chdir('/content/nerf-pytorch')\n",
    "\n",
    "print(f\"Current directory: {os.getcwd()}\")\n",
    "print(\"\\nFiles in directory:\")\n",
    "!ls -lh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Install Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "!pip install imageio imageio-ffmpeg configargparse scikit-image tqdm matplotlib -q\n",
    "\n",
    "print(\"✓ Dependencies installed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Verify Dataset and Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "print(\"Checking required files...\\n\")\n",
    "\n",
    "# Check Python files\n",
    "required_files = [\n",
    "    'run_nerf_with_metrics.py',\n",
    "    'run_nerf_helpers.py',\n",
    "    'load_blender.py'\n",
    "]\n",
    "\n",
    "for f in required_files:\n",
    "    if os.path.exists(f):\n",
    "        print(f\"✓ {f}\")\n",
    "    else:\n",
    "        print(f\"✗ {f} NOT FOUND\")\n",
    "\n",
    "# Check config\n",
    "if os.path.exists('configs/lego_config.txt'):\n",
    "    print(f\"✓ configs/lego_config.txt\")\n",
    "elif os.path.exists('lego_config.txt'):\n",
    "    print(f\"✓ lego_config.txt (will move to configs/)\")\n",
    "    !mkdir -p configs\n",
    "    !mv lego_config.txt configs/\n",
    "else:\n",
    "    print(f\"✗ lego_config.txt NOT FOUND\")\n",
    "\n",
    "# Check dataset\n",
    "print(\"\\nChecking dataset...\\n\")\n",
    "base_path = 'data/nerf_synthetic/lego'\n",
    "\n",
    "if os.path.exists(base_path):\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        transform_file = f'{base_path}/transforms_{split}.json'\n",
    "        if os.path.exists(transform_file):\n",
    "            with open(transform_file, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            n_frames = len(data['frames'])\n",
    "            print(f\"✓ {split}: {n_frames} images\")\n",
    "        else:\n",
    "            print(f\"✗ {transform_file} not found\")\n",
    "else:\n",
    "    print(f\"✗ Dataset not found at {base_path}\")\n",
    "    print(\"\\nLooking for dataset in other locations...\")\n",
    "    !find . -name \"transforms_train.json\" -type f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Preview Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the configuration\n",
    "print(\"Configuration for training:\\n\")\n",
    "if os.path.exists('configs/lego_config.txt'):\n",
    "    !cat configs/lego_config.txt\n",
    "else:\n",
    "    print(\"Config file not found. Creating default config...\")\n",
    "    !mkdir -p configs\n",
    "    \n",
    "    config = \"\"\"expname = lego_metrics\n",
    "basedir = ./logs\n",
    "datadir = ./data/nerf_synthetic/lego\n",
    "dataset_type = blender\n",
    "\n",
    "no_batching = True\n",
    "\n",
    "use_viewdirs = True\n",
    "white_bkgd = True\n",
    "lrate_decay = 500\n",
    "\n",
    "N_samples = 64\n",
    "N_importance = 128\n",
    "N_rand = 1024\n",
    "chunk = 8192\n",
    "netchunk = 131072\n",
    "\n",
    "half_res = False\n",
    "\n",
    "i_print = 100\n",
    "i_weights = 10000\n",
    "i_testset = 25000\n",
    "i_video = 50000\n",
    "\"\"\"\n",
    "    \n",
    "    with open('configs/lego_config.txt', 'w') as f:\n",
    "        f.write(config)\n",
    "    \n",
    "    print(\"✓ Created default config\")\n",
    "    !cat configs/lego_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Start Training\n",
    "\n",
    "**⚠️ IMPORTANT**: This will take 4-6 hours. Make sure:\n",
    "1. You're using a GPU runtime (Runtime → Change runtime type → GPU)\n",
    "2. Keep the tab open or use Colab Pro to avoid timeouts\n",
    "\n",
    "The training will:\n",
    "- Run for 200,000 iterations\n",
    "- Save checkpoints every 10,000 iterations\n",
    "- Evaluate on test set every 25,000 iterations\n",
    "- Print progress every 100 iterations\n",
    "- Save all metrics automatically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start training\n",
    "!python run_nerf_with_metrics.py --config configs/lego_config.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: View Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from IPython.display import Image, display\n",
    "\n",
    "# Load and display summary metrics\n",
    "print(\"=\"*60)\n",
    "print(\"TRAINING SUMMARY\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "with open('logs/lego_metrics/summary_metrics.json', 'r') as f:\n",
    "    summary = json.load(f)\n",
    "\n",
    "for key, value in summary.items():\n",
    "    if value is not None:\n",
    "        print(f\"{key}: {value}\")\n",
    "\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Display plots\n",
    "print(\"\\nTraining Metrics Plot:\")\n",
    "if os.path.exists('logs/lego_metrics/training_metrics.png'):\n",
    "    display(Image('logs/lego_metrics/training_metrics.png'))\n",
    "else:\n",
    "    print(\"Plot not found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 9: Analyze Results (Optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detailed analysis if analyze_results.py exists\n",
    "if os.path.exists('analyze_results.py'):\n",
    "    !python analyze_results.py \\\n",
    "        --log_dir logs/lego_metrics \\\n",
    "        --save_plot logs/lego_metrics/detailed_analysis.png \\\n",
    "        --export_table logs/lego_metrics/results_table.md\n",
    "    \n",
    "    # Display detailed analysis\n",
    "    print(\"\\nDetailed Analysis:\")\n",
    "    if os.path.exists('logs/lego_metrics/detailed_analysis.png'):\n",
    "        display(Image('logs/lego_metrics/detailed_analysis.png'))\n",
    "else:\n",
    "    print(\"analyze_results.py not found, skipping detailed analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 10: Download Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import files\n",
    "\n",
    "# Zip all results\n",
    "!cd logs && zip -r lego_metrics_results.zip lego_metrics/\n",
    "\n",
    "print(\"✓ Results zipped\")\n",
    "print(\"\\nDownloading results...\")\n",
    "\n",
    "# Download the zip file\n",
    "files.download('logs/lego_metrics_results.zip')\n",
    "\n",
    "print(\"\\n✓ Download started\")\n",
    "print(\"\\nKey files in the zip:\")\n",
    "!zipinfo -1 logs/lego_metrics_results.zip | head -20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 11: Quick Metrics Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick extraction of key metrics for your report\n",
    "import json\n",
    "\n",
    "with open('logs/lego_metrics/summary_metrics.json', 'r') as f:\n",
    "    metrics = json.load(f)\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"KEY METRICS FOR YOUR REPORT\")\n",
    "print(\"=\"*60)\n",
    "print(f\"\\nTraining Time: {metrics.get('total_training_time_hours', 'N/A'):.2f} hours\" if metrics.get('total_training_time_hours') else \"Training Time: N/A\")\n",
    "print(f\"Test PSNR: {metrics.get('best_test_psnr', 'N/A'):.2f} dB\" if metrics.get('best_test_psnr') else \"Test PSNR: N/A\")\n",
    "print(f\"Test SSIM: {metrics.get('avg_test_ssim', 'N/A'):.4f}\" if metrics.get('avg_test_ssim') else \"Test SSIM: N/A\")\n",
    "print(f\"Avg Step Time: {metrics.get('avg_step_time', 'N/A'):.4f} seconds\" if metrics.get('avg_step_time') else \"Avg Step Time: N/A\")\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"\\nCopy these values for comparison with 3DGS!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Troubleshooting\n",
    "\n",
    "### Out of Memory Error\n",
    "If you get OOM errors, reduce batch sizes. Create a new cell and run:\n",
    "```python\n",
    "# Edit config to reduce memory usage\n",
    "config = open('configs/lego_config.txt').read()\n",
    "config = config.replace('N_rand = 1024', 'N_rand = 512')\n",
    "config = config.replace('chunk = 8192', 'chunk = 4096')\n",
    "with open('configs/lego_config.txt', 'w') as f:\n",
    "    f.write(config)\n",
    "print(\"✓ Config updated with lower memory settings\")\n",
    "```\n",
    "\n",
    "### Session Timeout\n",
    "- Use Colab Pro for longer sessions\n",
    "- Keep browser tab active\n",
    "- Consider reducing iterations for testing\n",
    "\n",
    "### Dataset Not Found\n",
    "Make sure your GitHub repo has the data in the correct location:\n",
    "- `data/nerf_synthetic/lego/transforms_train.json`\n",
    "- `data/nerf_synthetic/lego/train/` folder with images"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
